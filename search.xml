<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[字节流字符流]]></title>
    <url>%2F2020%2F04%2F12%2F%E5%AD%97%E8%8A%82%E6%B5%81%E5%AD%97%E7%AC%A6%E6%B5%81%2F</url>
    <content type="text"><![CDATA[Java基础篇 IO系列之字节流、字符流 本文基于JDK 1.8，主要讨论的类都出自 java.io 前言Java的基础IO的最终实现都是调用的native，也就是用c实现的，所以从技术上来讲并没有太多新颖的东西，本文作为基础篇更多的是讨论接口定义和设计理念，不过多涉及操作系统层面的IO实现(那个放在《深入理解计算机系统》里面来说) IO类的划分JDK中的字符流和字节流的抽象是基于同一个抽象概念：流(Stream)，在这个抽象概念中，数据被比作是管道中的水，而数据的输入输出(IO)操作可以视为水在管道中的流动。 基于上面的抽象定义，JDK从两个维度对IO类进行了划分，首先是按照流的方向将IO类划分为了输入流和输入流两个大类，此外按照流中的数据类型不同，将IO类划为了字符流(更多的只是一个抽象概念，底层实现其实还是依赖字节流)和字节流两个大类，因此总得来说可以分为4类，具体划分如下： 输入流 输出流 字节流 字节输入流(InputStream) 字节输出流(OutputStream) 字符流 字符输入流(Reader) 字符输出流(Writer) 上述是对于JDK中IO类的一个宏观分类，具体落实到每一种流的具体实现的时候，还需要考虑更多的细节，例如对于字节输入流而言，它的数据来源是什么？是一个String类，还是一个File类，还是一个byte数组？这些问题我们放到后面再来详细分析，现在的话只需要理解上面这些抽象概念，在理解这些概念之后，再来看具体的JDK的IO类的定义和实现就会比较轻松了。 字节流最基础的IO工具类 字节输入流字节输入流InputStream本身是一个抽象类，按照数据来源不同拥有多个实现类，这些数据来源分别为： 字节数组 String对象 文件 管道 其他的字节输入流 其他数据源，例如Internet连接 我们先来逐个分析一下所有的InputStream的实现类，看一下它们都用来干什么： 类名 作用 备注 ByteArrayInputStream 顾名思义就是用于读取字节数组的类 FileInputStream 从文件中读取字节数据 底层调用是的open0和read0这两个native方法 ObjectInputStream java原生的反序列化类，用于读取对象 通常和ObjectOutputStream搭配使用 PipedInputStream 用于创建管道 可用于多线程读写场景必须和PipedOutputStream搭配使用 SequenceInputStream 用于拼接多个InputStream，将其合并为一个 现在已经很少使用 FilterInputStream 修饰器，用于修饰InputStream 这是最为特殊的一个实现类 上面这些实现类中很多从名字上就能看出作用的就不再赘述了，具体的接口可以参考JavaDoc，这里还需要再提一下的是ObjectInputStream，PipedInputStream和FilterInputStream ObjectInputStream是用来对被ObjectOutputStream序列化的类进行反序列化的，是JDK的原生序列化类(具体的序列化逻辑以后会专门用一篇序列化主题的文章进行介绍) PipedInputStream 是用来和PipedOutputStream搭配使用的，用这两个类可以形成一个有向管道，有向是指数据只能从PipedOutputStream中流向PipedInputStream，这个管道支持多线程写和多线程读，可以用来实现一个简单的生产者-消费者模型 FilterInputStream 是最最特殊的一个实现类了，它本身没有任何实际功能，只提供对于InputStream类的包装，也就是 装饰者模式 中的装饰器，使用这个装饰器，我们可以对上述的所有 InputStream实现类进行功能增强 最后我们再来看看装饰器FilterInputStream有哪些子类，以及它们主要提供了什么作用： 类名 作用 备注 BufferedInputStream 提供一个缓冲区，每次读写操作都在缓冲区中进行 DataInputStream 提供对基础类型的解析，可以直接将字节转换为基础数据类型读出 PushbackInputStream 支持回退操作，可以把已读出的数据再放回流中 几乎没有使用 字节输出流字节输出流OutputStream本身也是一个抽象类，按照数据的去向不同拥有多个实现类，这些数据去向分别为： 字节数组 文件 管道 具体实现类有： 类名 作用 备注 ByteArrayOutputStream 向内存中一块空间写入字节数据 FileOutputStream 将字节数据写入指定文件中 底层调用的是open0，write等native方法 ObjectOutputStream 序列化Java Object对象使用 通常和ObjectInputStream搭配使用 PipedOutputStream 用于构建管道 必须和PipedInputStream搭配使用 FilterOutputStream 提供装饰功能使用 作用效果和FilterInputStream类似 我们可以看到输出流和输入流大体上都是一样的，了解了输入流基本上自己就能推导出有哪些对应的输出流，最后我们再来看一下FilterOutputStream的子类： 类名 作用 备注 BufferedOutputStream 同BufferedInputStream作用类似 DataOutputStream 同DataInputStream作用类似 PrintStream 最特殊的输出流，提供各种类似的数据输出 常使用的System.out其实也是PrintStream 字符流字符流更多的是对字节流的补充，用于提供面向字符以及unicode编码的IO功能。 字符输入流Reader 同样是一个抽象类，提供最原始的定义，我们先来看看Reader的具体的实现类： 类名 作用 备注 BufferedReader 同BufferedxxxStream类似，提供一个缓存区用于操作 CharArrayReader 类似于ByteArrayxxxStream,用于读取字符数组 FilterReader 类似FilterxxxStream，不过有些许不同，子类较少 InputStreamReader 连接InputStream和Reader，可以将字节流转换为字符流 PipedReader 同PipedInputStream类似，必须和PipedWriter搭配使用 StringReader 顾名思义就是读取String对象 还有BufferedReader的子类： 类名 作用 备注 LineNumberReader 提供当前读取的行号，不过这里的行号只是一个计数器，不会影响实际的读取文件位置 InputStreamReader的子类： 类名 作用 备注 FileReader 用于读取文件，其底层是调用的FileInputStream FilterReader的子类： 类名 作用 备注 PushbackReader 同PushbackxxxStream类似，提供回退功能 可以看到字符流的实现类大多数都是和字节流一一对应的，只是类的继承结构有所不同，唯一有差别的就是InputStreamReader类，该类的构造参数为一个InputStream，可以按照指定的编码方式将字节流转为字符流 字符输出流Writer同理也是一个抽象类，老规矩先看看它的子类： 类名 作用 备注 BufferedWriter 提供缓冲区用于操作 CharArrayWriter 写字符数组 FilterWriter 提供装饰功能 OutputStreamWriter 连接OutputStream，可以将字节流转换为字符流 PipedWriter 必须和PipedWriter搭配使用,用于创建管道 PrintWriter 作用同PrintStream类似，不同之处在于PrintStream的输出永远是字节的形式，而PrintWriter 是字符 StringWriter 用于写String对象，内部是个StringBuffer对象 OutputStreamWriter 的子类： 类名 作用 备注 FileWriter 写文件 Writer同Reader，基本是是一一对应，没有太多的变化，需要注意的一点是PrintWriter和PrintStream的使用，在我看来PrintStream完全可以使用PrintWriter来代替，因为这两者的序列化接口都是一致的，且PrintWriter的构造函数中也支持传入PrintStream参数。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>字节流</tag>
        <tag>字符流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解计算机系统-第一章]]></title>
    <url>%2F2020%2F03%2F29%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F-%E7%AC%AC%E4%B8%80%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[深入理解计算机操作系统-第一章一些概念文本文件：使用ASCII字符表示的文件 二进制文件：除文本文件之外都为二进制文件 字：总线传输的字节数组，可以为4或者8个字节，视具体的硬件设备而定，是计算机系统参数 寄存器：大小为一个字的存储设备 c语言编译过程实例代码#include&lt;stdio.h&gt; int main(){ printf(&quot;hello world\n&quot;); return 0; } 转换过程 hello.c(文本) -&gt; 预处理器(CPP) -&gt; hello.i(文本) hello.i(文本) -&gt; 编译器（CCl）-&gt; hello.s（文本） hello.s（文本）-&gt; 汇编器(as) -&gt; hello.o（二进制） hello.o + printf.o -&gt; 链接器(ld) -&gt; hello 预处理将#include中包含的头文件stdio.h内容插入hello.c中，生成hello.i，其两者都是文本文件 编译编译器将hello.i中的c语言语法翻译为汇编语法，生成文件hello.s ，其两者都为文本文件 汇编汇编器将hello.s 文件翻译为机器语言，生成文件hello.o,hello.o为二进制文件 链接链接器将hello.o中使用到的库函数printf对应的可执行文件printf.o链接起来，生成最终的可执行文件hello 系统硬件总线 贯穿系统的电子通道，用于在各部件之间传递字节信息 总线传送的数据单位是字(word)，也就是定长的字节数组，通常为4个字节（32位）或8个字节（64位） IO设备 IO，即输入输出系统，是系统与外部世界的联系通道，例如：鼠标、键盘、显示器、磁盘等 IO设备通过控制器或者适配器与IO总线相连 控制器：IO设备本身已有的或是主板上有的，例如：USB控制器，磁盘控制器 适配器：主板插槽上的一张卡，例如：图形适配器(显卡)，网络适配器(网卡) 主存 临时存储设备，存储程序运行时数据或程序 从物理角度上看是一组DRAM（动态随机存取存储器） 处理器 即cpu，是用于解释或者执行存储在主存中指令的引擎 组成：寄存器文件（多个寄存器）、程序计数器(PC)、ALU(算数/逻辑单元) 如何运行一个程序以上面已经编译好的hello文件为例 执行命令为 ./hello 当使用键盘输入上述字符之后，shell程序会将该字符串读入寄存器，然后再将其放入主存中(memory) 当敲击回车键后，shell会执行一系列指令来加hello文件 从磁盘加载数据至主存使用的是DMA(直接存储器存取)技术，不经过寄存器，hello文件中的代码和数据都会被通过这种方式加载到主存中 当hello文件被加载至主存中之后，处理器就会开始执行代码，在本例子中具体的步骤就是从主存中读取”hello work\n”这段字符串至寄存器，随后输出至显示器 关于Cache 用于连接读写数据差距较大的存储设备，尽可能提高整体读写效率 分层 L0 (寄存器) L1 (SRAM 高速缓存) L2 (SRAM 高速缓存) L3 (SRAM 高速缓存) L4 (DRAM 主存） L5 (本地磁盘) L6 (远程磁盘) 操作系统如何管理硬件资源涉及到3个抽象概念 文件 （IO设备的抽象） 虚拟内存 (IO设备 + 主存的抽象) 进程 (IO设备 + 主存 + 处理器的抽象) 进程进程是对一个正在运行的程序的抽象 任何时刻单处理器系统都只能处理一个进程的数据 当要切换进程的时候就需要操作系统把当前进程的信息，例如pc，寄存器文件，主存等状态保存下来，然后将控制权交给下一个进程，这个过程就是上下文切换 上下文切换是通过系统调用(system call)完成的 线程线程是进程中的一个执行单元，所有线程都共享一个进程上下文，线程之间数据共享比进程数据共享要更容易 虚拟内存虚拟内存是主存和文件的抽象，主要作用是为进程提供一个假象，即当前每个进程都在独占地使用主存。 每个进程看到的虚拟内存都是一样的，由多个固定的区构成，从上至下分别为： 内核虚拟内存（内核保留区域） 栈(编译器实现函数调用) 共享库(共享的代码以及数据) 堆(运行时可动态扩缩容) 程序代码和数据(代码和常量) 文件文件即字节序列，所有IO设备都被当做是一个文件，系统中的所有输入输出都是由一组被称为 Unix I/O 的系统函数调用读写文件来完成的。 Amdahl定律即阿姆达尔定律，用来分析系统性能，其主要思想如下： 假定当前系统执行某个应用程序的时间为：Told 假设系统某部分所需执行时间与该时间的比例为：α 该部分性能提升比例为 k，也就是该部分初始所需的执行时间为 α Told，现在需要的时间为 （α Told）/k 那么我们能够计算出优化之后的执行时间 ： Tnew = (1 - α) Told + （α Told）/k = Told * （（1- α） + α/k） 从而能够得出加速比 S = 1/[( 1 - α) + α/k] 这个加速比的具体含义是什么呢，举个例子，我们假设α = 0.6 ，k等于3，那么计算出来的S 为：0.67，用白话来说的话，就是你得把这个系统60%的部分的性能提高3倍，才能到达让这个系统性能整体提升1.67倍的效果。 阿姆达尔定律的含义用一句话来描述就是：想要显著加速整个系统，必须提升全系统中相当大部分的速度。 其他多核处理器 多个物理核通过L3Cache连接 单核通过超线程技术执行多个控制流 虚拟机操作系统的抽象]]></content>
      <categories>
        <category>基础学习</category>
      </categories>
      <tags>
        <tag>日常学习</tag>
        <tag>基础</tag>
        <tag>os</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作年鉴]]></title>
    <url>%2F2020%2F03%2F28%2F%E5%B7%A5%E4%BD%9C%E5%B9%B4%E9%89%B4%2F</url>
    <content type="text"><![CDATA[工作年鉴 时间于每个人而言都是公平的，不会为任何人停留，与其在已经无能为力的时候悲叹时不待我，不如记录下从现在开始的每一秒自己是怎么过的，活得明明白白 前言到现在为止工作已经快4年了，期间也经历过很多事情，现在想来，无论是刚毕业时的面试，还是后面的第一次到公司报道，第一次实际参加工作，以及后面的绩效考核，晋升，离职等等，这些事情至今还像是发生在昨天一样，回忆起来有苦有甜，百味杂陈，都说以史为鉴可以明得失，现在自己也到了人们常说的工作中的第一个分水岭 3~5 年，所以在这里回顾一下过去这几年的工作经历总结一下自己这几年的得失，包括一些成长，一些遗憾，一些感受，不过这也不算是很正式规划总结什么的，所以可能会比较乱，流水账形式，想到哪里就写到哪里。 工作经历找工作(2015)刚开始找工作应该是在大四上学期15年底，现在想来那个时候的自己真的是只各种意义上的菜鸡，由于自己大学期间全在搞ICPC，基本上都是写写console代码，根本没有写过工程代码，更好笑的是因为那个时候都只写c/c++,结果后面找工作的时候发现只找c找工作不怎么好找(因为c我也是菜鸡)，所以花了几天学了一下java语法，背了几个经典面试题，然后投简历就开始投C和Java两个岗位了，真不知道哪来的自信，不过最后运气还是挺好的，在成都参加了各种面试被拒之后在最后一天的面试里面被点评给捡走了我这个菜鸡，当初在成都面试的经历现在想来也是历历在目，印象最深的一天就是和fufu一起上午面美团下午面腾讯，那是真的面了一天，期间辗转各大酒店，饭都差点吃不上，后面还有一些有意思的事比如秋哥一起去一个小作坊面试，那家所谓的公司居然在居民楼里，找了半天都找不到，还有和fufu秋哥一起在酒店挤一张床，结果半夜隔壁传来奇怪动静的魔幻经历😂 第一年(2016.7 ~ 2017.7)第一年应该算是成长最快同时也是过得最开心的一年，那个时候刚入职，啥都不懂，工程代码没写过一行，慌得一批，就怕试用期被干掉了，不过好在那个时候的同事们都很nice，很有耐心地带我这只菜鸡入门，帮我融入团队等等。 第一年主要的工作就是熟悉工作中使用的技术栈，然后就是熟悉团队业务能够自己独立完成需求，那个时候团队虽然小但是维护的应用和涉及到的技术都挺多的，有最基础的Web项目，提供RPC的service项目，以及依靠分布式调度系统的定时任务，还有一些前后端分离的项目等等，足够一个应届生去了解和成长的了，仔细想了一下，自己在这一年的技能成长顺序应该是这样的： 入门的时候学会了使用maven和git，这是项目搭建和团队协作必要的两个东西，还有熟悉了intellij这个ide 做web项目和一些前后端分离项目的时候学会了MVC架构，以及SSM(Spring + SpringMvc/Struts2 + mybatis)这些框架,了解了Tomcat这个容器，还有一些前端的零碎知识点吧，包括js和ajax这些，不过上面说的这些都仅限于使用层面，原理都不甚了解 做service项目的时候第一次接触了RPC的概念，同时还接触了mysql，分布式数据库链接，分库分表，主从同步这些 同时还有了解到一些分布式配置中心的概念，知道了zookeeper这个名词 后面陆陆续续补了一些java相关的基础，例如IO啊，并发啊之类的 后面就是一些业务熟悉了，除了业务知识之外还因为在日常工作中采用的是敏捷开发，所以也接触到了一些scrum相关的知识，当时用的工具应该是腾讯的tapd，讲道理挺好用的 第二年(2017.7 ~ 2018.7)到了第二年基本上业务熟悉得差不多了，负责的应用和日常需求也开始多起来了，同时这一年里面自己也接到了开发一个高并发服务的任务，将平时使用到的框架之类的工具进行了一些深入的学习，在加上当时的团队有每周做技术分享的习惯，技术氛围挺浓的，大家都会仔细去专研一些问题，所以在这一年里面主要成长是技术深度的一个提升，具体的内容应该是这样的： 首先是学了一波Tomcat的架构，看了一本书叫做《深入剖析Tomcat》还是什么的，记得讲的是tomcat 5.0的内容，后面自己也找了个7.0版本的源码看了一部分，不过具体的代码现在已经记不清楚了，最大的收获应该是学到了Tomcat的多容器划分和统一生命周期管理这样的架构，这个在后面的工作中也有使用到，和web相关的还有一些负载均衡相关的东西，例如4/7层代理，反向代理这些概念，以及nginx等，不过都只是了解概念，没怎么深入 随后的话应该是spring的学习，把spring 用于实现DI（dependency injection）的Ioc 容器部分看了一遍，当然看了IOC还得看AOP，于是把proxy方式和cglib方式的AOP代码也看了一遍，后面还看了springmvc的部分代码。 看了spring之后ssm三件套中的mybatis当然也不能漏掉，顺便就研究了一下mybatis和spring是怎么集成的（就是aop），以及mybatis是怎么封装jdbc的，不过现在想来貌似源码都忘得差不多了😂 后面的话就是mysql相关的学习了，其实主要就是innodb的学习吧，了解了一波索引的数据结构（其实都只是概念了解）理解诸如最左匹配原则这些东西，当然也在线上sql调优的过程中学会了使用explain这类工具，然后就是一些常规的东西，例如innodb的事务隔离级别，ACID的特性，以及mvcc，日志先行，undo redo，binlog这些概念，不过都只是概念性的学习，没有真正去翻过源码什么 最后的话就是高并发服务那一套了，先是看了点评当时的RPC框架pigeon的源码，了解了包括RPC协议定义和序列化，服务注册发现，负载均衡策略这些东西，然后是缓存部分，当时用的是封装之后的redis，不过为了容灾也引入了tair 的ldb（其实就是level db），在缓存之后为了保障稳定性也用了很多手段，包括物理层面的异地双中心部署，代码层面的熔断降级保护(用的点评自研的rhino，源码没有去看不过用起来和netflix的Hystrix挺像的，原理应该也差不多)，db 层面的分库分表等 当然在这个过程中还陆陆续续补了一些java基础，看了些jvm相关的书籍，简单学了一下gc，类加载，jvm内存模型，jmm模型以及jdk的部分类的源码，像集合类相关的hashmap，concurrenthashmap，多线程相关的ThreadPool，ThreadLoad，并发相关的Atom类，ReentrantLock 等 这一年新的东西没有学太多，不过基本上把自己平时用的东西的原理都弄懂了，虽然没有都真正去看过源码，至少理论知识还是都了解了一二。 第三年(2018.7 ~ 2019.7)这一年其实可以分成两部分来说，因为种种原因，本来打算转岗回成都的，结果后面阴差阳错就跑到了杭州，去了阿里，体验了人生中第一次跳槽，正确与否至今不知道，只能说自己的选择自己负责吧。 跳槽是在9月份的时候，所以这一年在点评的日子只有2个多月吧，这段时间其实也没怎么学新东西，就听了几个同事们的分享，像python爬虫，搜索引擎，以及guava相关的一些工具类，自己也准备了一下面试的东西。 9月之后就入职阿里了，到了阿里之后最开始感受到的就是所谓的价值观吧，价值观这个东西人人都在提，我也觉得每一条都挺有道理的，但就是不知道到底有多少人真正按照这个价值观在做事，至少我看到的提到价值观的时候大多数是在把价值观当做管理工具在使用（这里想插一句我对于企业文化的思考，我一直认为企业文化不是喊一些口号，做一些横幅就能有的，真正的文化应当是员工的日常的行为方式，因为员工组成了公司，员工的行为组成了公司的行为，公司的行为中体现出来的才是真正的企业文化），随后感受到的可能就是现在大家耳熟能详的”福报”，不过对我而言还好，之前在点评的时候基本上是1065，偶尔待到8点等一个餐补在走，在阿里这边通常是1095，周五通常6点或者7点就走了，所以实际上班时间差不多，唯一比较坑的就是我们这个团队经常半夜值班或者大促值班，半夜值班可能就是到晚上3点左右，大促值班就直接通宵了，实属扛不住。 在阿里这边做事情的方式和做的事情与点评都有很大的不同，比起互联网公司来说，我们团队这边做的事情更像是传统IT企业，我们团队在技术方面做的事情主要就是维护一个离线数据文件，然后每天对全网几百个应用进行推送，这个离线文件可以看做一个小型只读数据库，技术栈的话其实没有太多梳理了一下大概有一下几个吧： netty，服务端和客户端之间的通信以及文件传输是通过netty来做的，所以顺便学习了一下netty，因为Nio这个概念其实之前就已经了解了，所以学习netty更大的收获应该是其使用的SEDA(Staged Event-Driven Architecture)架构,这是之前没了解到的一个点 java 内存映射，因为离线文件的加载有部分数据是采用内存映射的方式进行加载的，这部分是之前没有使用过得东西，不过现在了解也不是很深，只知其理论基础是基于zero copy sqlite，因为有部分文件的存储形式是sqlite，所以又去了解了一下sqlite的使用，看了一下sqlite-jdbc的源码，因为sqlite的源码是c写的所以没怎么去看 除次之外就是对阿里的中间件学习，因为之前在点评的时候就已经了解过挺多中间件的原理了，所以一些重复功能的中间件就没有去看过了，基本上都是看新的中间件，不过说真的，在阿里最大的失望可能就是它的中间件建设了，技术含量因为没有去看过源码所以不评价，但是就用户使用体验来说，感觉差了点评几条街把，始终有一种古老的感觉，没有跟上时代的发展，就像是在使用上古代码编程，而且内部的中间件多且杂，功能重复的多，没人维护的也挺多，半成品中间件用起来有多糟心懂的人都懂，就不细说了，不过也有一些感觉很好用的东西，比如在外面没有听说过的： Pandora，这是一个类隔离容器，通常与tomcat或者spring-boot搭配使用，能够做到二方包级别的类隔离，详细一点说就是通过修改不同二方包的类加载器从而实现，当不同二方包中包含相同类的时候，能够做到自己引用自己需要的版本的类，不会与其他二方包产生冲突 另外在阿里还学会了一些软技能，例如： 之前不怎么会的ppt xmind以及markdown以及一些画图工具 甚至还因为年会需要剪视频学了一波pr 第四年(2019.7 ~ 2020.7)也就是今年，这一年刚好也是自己25岁的一年，自己也想了很多东西，包括未来的人生规划和工作方向这些，包括创业，出国留学等，总得来说思考地比较多。 这一年的技术学习基本上转换了方向，大体上分为了两部分，一部分是基础学习，一部分是未知领域探索 基础学习部分主要是一些底层技术，例如： 编译原理 OS，linux 网络，tcp/ip Jvm 算法 未知领域的学习就比较多了，现在比较火但是自己又没怎么了解的东西基本上都去粗浅地看了一遍，例如： 云原生 区块链 docker相关的 虚拟机技术，k8s等 同serviceless 相关的 service mesh等，不过感觉service mesh对于小公司而言没啥用，对大公司的作用还有待时间验证 spring 相关的，spring-boot，spring-cloud等 go 后续还打算学习一下AI方面的知识 除了技术之外，今年主要的学习重心是在业务逻辑学习上，今年的计划是打算把从卖家上架商品，到用户购买商品，在到商家发货，用户收货，核销等整个链路的业务流程都了解一遍，并且详细了解商家发品链路，把后面对应的商品模型，产品模型，类目模型都搞透彻 公司经历美团点评(2016 ~ 2018)在美团点评的工作方式是采用的敏捷开发，通常是一周一个迭代，具体工作流程如下： 在点评一个垂直业务中可能会涉及到7个以上团队，分别为销售团队，运营团队，产品团队，视觉团队，后端开发团队，前端开发团队，测试团队等，每个团队在组织架构上都是分开的，分别由各自团队的上级管理，但在这个垂直业务中是可以看做一个整体的，基本上不会有变动，通常的工作方式是销售签单推广，运营运营，产品经理做市场调研从市场或者销售和运营处收集需求然后同开发团队进行沟通，确定功能细节和上线时间。 每周五产品经理会约会同技术人员(前后端开发 + 测试)做需求评审，产品展示prd，技术同学评估技术可行性，并将需求进行拆分，给出每个任务所需具体工时 每周一技术同学会开会认领上面需求，每个人的工时按照一天6小时，一周4天计算，每个人会认领差不多24个工时的任务，这些任务就是本周的主要工作。 每天早上10点左右会开一个站立会，每个人用几分钟时间同步自己昨天的进度或是遇到的困难，以及今天要做的任务 在开发开发完之后，就是前后端同学联调，联调通过后自测，自测完成后提交给测试同学测试，测试同学测试无误之后，由产品和视觉同学进行uat，uat通过后就上线 除此之外，之前所在的team还有一个传统就是技术分享，每周会选择一个大家都有空的时间段(大多数情况是下午14点之后的某个时间点)大家一起放下手上的活去参加一个技术分享，分享是通过自愿报名的方式，通常需要提前一周报名，然后告知大家下周要分享的内容，然后大家会先去了解一下相关内容的前置知识点，分享内容不定，可以是任何自己会的东西。 在点评的日子过得比较轻松，而且同事们之间的氛围也都很好，现在想来可能这段经历最大的收获除了入门了码农这个职业之外，就是认识了一群工作上的同事，生活上的朋友吧，不得不说点评的同事们提高了我对同事关系的期望值，降低了我对同事的容忍度。 阿里巴巴(2018 ~ 2020)在阿里的工作方式，更多地是类似传统企业，类似瀑布流那样，而且现在做的是中台所以接触的团队也没有那么多了，基本上就是自己团队里面在玩。 阿里这边kpi比较重，所以每个人的工作基本上是围绕着KPI展开的，在每个S开始的时候，每个人都要同leader定下自己的KPI考核项和目标完成度，然后接下来的半年，就围绕着这些kpi项开始做事情。 通常一个项目上线的流程是这样的，团队内部自己提出需求或者外部团队需要支持提出需求(现在大多数情况都是团队内部自己想的需求),随后选出一个人做项目pm，再选几个人作为开发资源，随后pm分解项目，把任务分配给每个人，然后定好阶段里程碑，随后就是开发人员开发，到项目节点的时候进行验收，开发完成之后就是自测(因为阿里这边的测试人员叫做测试开发，自己也要开发东西完成kpi，所以很少会来帮我们测试)，上线，这个过程通常会持续几个月。 这中间有个不知道是不是阿里特色的东西，就是在项目开始之前约上各个业务方的老板搞一个盛大的kick off，一直没能明白意义何在。]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>随想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈谈B-Tree 和 B+Tree]]></title>
    <url>%2F2020%2F02%2F22%2FBTree%2F</url>
    <content type="text"><![CDATA[谈谈B-Tree 和 B+Tree前言周末在看《High Performance Mysql》（中文译为《高性能Mysql》）一书的时候，在index部分看到了B-Tree的概念，实际上这个名词于我而言并不陌生，毕竟之前为了应付面试的时候翻过很多博客，但今天再次看到这个名词时突然回忆不起来B-Tree到底是个什么东西了，于是用度娘去搜了一下，结果搜出来的定义千奇百怪（中文社区里面真的是一堆错误文章抄来抄去，甚至有人说B-Tree是Balance Binary Tree，还假装很懂的说作者是Adelson-Velskii和Landis，看得我一脸懵逼，你这样让AVL-Tree情何以堪？），后面又去外网搜了一下，也发现挺多不一样的定义的，真的是越看越不懂了，后面没办法了就直接找到了原作者R. BAYER and E. MCCREIGHT1971年发布的论文看了一遍，算是真的去了解了一下这个数据结构。 什么是B-Tree关于B-Tree这个名词的说明首先B-Tree这个名词是在R. BAYER and E. MCCREIGHT 1971年发布的一篇文章《Organization and Maintenance of Large Ordered Indexes》中提到的,原文如下： The pages of the index are organized in a special datastructure, so-called B-trees. 看到了吧，虽然B-Tree确实是一颗自平衡的树但是B-Tree的全名就是”B-Tree”,而不是什么Balanced Tree之类的缩写，可以说Balanced Tree包含B-tree但不仅仅只有b-tree ps:其实我更觉得这个B是作者 R. BAYER 的缩写 B-Tree 的定义在文章中，B-tree的定义如下： 假定h为大于等于0的整数，k为一个自然数，那么满足以下条件的有向树T (T ∈ τ(k,h) )就被称为B-Tree： 根节点到所有叶子节点的路径长度都相同，且该路径节点数为h 除根节点和叶子节点之外，每个节点都至少包含k+1个子节点；对于根节点而言要么它同时也是叶子节点，要么至少包含2个子节点 每个节点最多包含2k + 1个子节点 是的你没看错，以上就是B-Tree的完整原始定义，就是这么简洁，没有什么花里胡哨的m阶cell(m/2)之类的东西 B-Tree在索引存储上的使用在上述定义的基础上，当使用B-Tree的节点作为索引储存的页的时候，B-tree还会有以下性质： 除了根页节点能保存的key的个数范围为1~2k之外，其他所有页节点能保存的key的个数的范围为k~2k 假定一个非叶子页节点为P，并且该节点上保存的key的个数为l，那么此节点上会有l+1个子节点 在页节点P 中的所有key都是单调递增的，形如:x0,x1,x2,……,xl;k &lt;= l &lt;= 2k,若P为根节点的话则：1 &lt;= l &lt;= 2k，此外在P中还会包含l + 1个指针用于指向P的子节点，这些指针用p0,p1,……,pl表示。 用于存储索引的一页，同时也是B-Tree的一个节点P的内部结构大概长得像下面这样： 引用一下论文中的图 p0,(x1,p1),(x2,p2),…..(xl,pl) 图中的p0是一个指针，指向所有key都小于x1的节点，随后就是索引里面包含的值x1，然后是x1附带的一些附加信息α1，随后是指针p1指向所有key都大于等于x1，但小于等于x2的节点……,最后是个指针pl，指向所有key都大于xl的节点，了解了这种结构之后就能知道为什么一个节点最多只能保存2k个key:因为指针数会等于子节点数等于2k+1，而key的个数会是指针数-1 B-Tree支持的基本操作查找对于B-Tree来说查找是比较简单的一个操作，我们假定要查的key 为 y，当前页为P 查询过程用语言来描述就是： 二分查找y在 P中是否存在，若存在则直接返回 若y在P不存在，并且P为叶子节点，则返回不存在 若y在P不存在，并且P不为叶子节点，则进入P的子节点，该子节点的指针为pi，满足xi-1 &lt; y &lt; xi+1 插入插入操作的逻辑其实很自然而然就能想到，首先，我们假设需要插入的元素为e，那么在不考虑平衡性的情况下，插入逻辑应该是这样的： 利用上面查找的逻辑，查找当前Btree中有无已存在的e 若有，直接返回插入成功 若无，则在搜索到最后一步的叶子页中插入e 那么上面的逻辑有一个很明显的问题，那就是叶子页的元素个数有可能超过2k，这在Btree的定义中是不被允许的，那么为了解决这个问题，我们就还需要做一步操作：页分裂 页分裂所谓的页分裂就是把一个拥有2k + 1个元素的页进行分裂，产出一个带父节点的新页，分裂之后原来的页中保留前k个元素，分裂出来的页中保留后k个元素，同时分裂前原页中的第k+1个元素会作为分裂出来的页的父节点。 就上述逻辑举个例子，假设原来的叶子节点为P,P中有2k个数据，P的父页为Q，那么该P中的数据存储情况应该是这样的： p0,(x1,p1),(x2,p2),…..(x2k,p2k) 当插入了e之后，现在的P会长这样： p0,(x1,p1),(x2,p2),…..,(xk+1,pk+1),……(x2k+1,p2k+1) 进行页分裂操作之后，P会长这样： p0,(x1,p1),(x2,p2),…..,(xk,pk) 产生的新页我们假设为P’，P’长这样： pk+1,(xk+2,pk+2),(xk+3,pk+3),…..,(x2k,p2k) 同时P’的父节点为： (xk+1,p’) 其中p‘指向的页就是产生的新页P’，随后把此节点再插入P的父页Q中，这样一次完整的页分裂操作就做完了。 所以，完整版的插入逻辑如下： 利用上面查找的逻辑，查找当前Btree中有无已存在的e 若有，直接返回插入成功 若无，则在搜索到最后一步的叶子页中插入e 插入e后叶子页元素个数没有超过2k，插入结束 插入e后叶子页元素个数超过2k，执行页分裂，并向上递归 删除关于删除，不考虑平衡性的话同样很容易就能想到一个朴素的操作办法，流程如下： 利用上面查找的逻辑，查找当前Btree中有无已存在的e 若无，直接返回删除成功 若有，直接删除该元素 那么这个操作流程肯定是有问题的，问题就出在删除元素上，一共有两个问题: 若该元素不在叶子页上，那一旦该元素被删除了，那该元素指向的子页怎么办？ 若该元素在叶子页上，那么一旦叶子页中的元素个数被删至低于k个了，怎么办？ 第一个问题比较好解决，如果该元素不在叶子节点上的话，就将该元素与它的右子节点的第一个元素进行交换，直到交换至叶子节点。 要解决第二个问题的话就需要引入一个新的操作：页合并 页合并页合并就是指把两个兄弟页合并为一个页的操作，具体怎么操作，我们等会用一个例子来说明，现在先约定一些名词，假设页Q中的元素e的左指针指向页P，右指针指向页P’,那么P和P’就被称为兄弟页，页合并操作都是在兄弟页之间进行的，同时页合并也有两种操作，分别被称为Catenation和Underflow CatenationCatenation发生在两个兄弟页中的元素之和小于2K的情况下，这种情况只需要把父页中的元素e给删掉，然后用e作为连接元素将P’中的所有元素合并至P中，随后删除掉页P’,用图表示如下： 合并前： 合并后： 当然父节点中的元素被删掉之后也可能出现元素个数小于k的情况，所以一旦执行了Catenation操作，必须要向上递归执行页合并操作 UnderflowUnderflow发生在两个兄弟页中的元素之和大于等于2k的情况下，这种情况下，我们首先还是先对这两个页做一遍Catenation操作，现在P中的元素个数就一定是大于等于2k + 1了，随后我们再对P执行一遍页分裂操作即可。 虽然页分裂操作会向父页中插入一个值，但是由于在执行页分裂操作前我们就从父页中删除了一个值，所以父页中的元素个数是不会变的，因此Underflow执行一次即可，无需递归执行 B-Tree java代码实现public class BTree { private int k; private Page root; public BTree(int k) { this.k = k; root = new Page(); } public Page getRoot() { return root; } /** * b-tree的节点 */ private class Page { private Element parent; private Element[] elements = new Element[(k + 1) * 2]; private int elementsSize = 1; Page() { elements[0] = new Element(null); elements[0].setIndex(0); elements[0].setPage(this); } public int getElementsSize() { return elementsSize; } public void setElementsSize(int elementsSize) { this.elementsSize = elementsSize; } public Element getParent() { return parent; } public void setParent(Element parent) { this.parent = parent; } public void setElements(Element[] elements) { this.elements = elements; } public Element[] getElements() { return elements; } public boolean addElement(Element value) { int index = bsSearch(elements, 0, elementsSize - 1, value.getV()); return addElement(index + 1, value); } public boolean addElement(int index, Element value) { value.setPage(this); for (int i = elementsSize; i &gt; index; i--) { elements[i] = elements[i - 1]; elements[i].setIndex(i); } value.setIndex(index); elements[index] = value; elementsSize++; return true; } /** * 返回小于等于v的第一个元素 * * @param v * @return */ public Element search(int v) { int index = bsSearch(elements, 0, elementsSize - 1, v); return elements[index]; } public Element getElement(int index) { return elements[index]; } public boolean delete(int index) { for (int i = index; i &lt; elementsSize; i++) { elements[i] = elements[i + 1]; if (elements[i] != null) { elements[i].setIndex(i); } } elementsSize--; return true; } /** * 返回小于等于当前v的第一个元素下标.若不存在则返回-1 * * @param elements * @param v * @return */ private int bsSearch(Element[] elements, int l, int r, int v) { for (; l &lt; r; ) { int mid = (l + r + 1) / 2; if (elements[mid].getV() != null &amp;&amp; elements[mid].getV() &gt; v) { r = mid - 1; } else { l = mid; } } return l; } } /** * 节点中的元素 */ private class Element { private Page rightIndex; private Page page; private int index; private Integer v; public Element(Integer v) { this.v = v; } public Page getRightIndex() { return rightIndex; } public void setRightIndex(Page rightIndex) { this.rightIndex = rightIndex; if (rightIndex != null) { rightIndex.setParent(this); } } public Integer getV() { return v; } public void setV(Integer v) { this.v = v; } public Page getPage() { return page; } public void setPage(Page page) { this.page = page; } public int getIndex() { return index; } public void setIndex(int index) { this.index = index; } } public Element search(int v) { return search(root, v); } public boolean insert(int v) { return insert(root, v); } public boolean delete(int v) { Element vEle = search(v); if (vEle == null) { return false; } // 叶子节点 if (vEle.getRightIndex() == null) { Page currentPage = vEle.getPage(); currentPage.delete(vEle.getIndex()); adjust(currentPage); } else { Page tmpPage = vEle.getRightIndex(); for (; ; ) { Element element = tmpPage.getElement(0); if (element.getRightIndex() != null) { tmpPage = element.getRightIndex(); continue; } element = tmpPage.getElement(1); vEle.setV(element.getV()); tmpPage.delete(element.getIndex()); adjust(tmpPage); break; } } return true; } private Element search(Page node, int v) { if (node == null) { return null; } Element element = node.search(v); if (element.getV() != null &amp;&amp; element.getV() == v) { return element; } return search(element.getRightIndex(), v); } private boolean insert(Page node, int v) { Element vEle = node.search(v); if (vEle.getRightIndex() == null) { node.addElement(new Element(v)); pageSplit(node); return true; } if (vEle.getV() != null &amp;&amp; vEle.getV() == v) { return true; } return insert(vEle.getRightIndex(), v); } /** * 0. 判断当前页是否需要进行页分裂，不需要直接返回 * 1. 将当前页节点 P 中间第k个元素 E(k) 取出 * 2. 新建一个页节点 Pn 将 E(k) 的右指针指向 Pn * 3. 将 P 中的第k+1 ~ 2k + 1个元素移至 Pn 中 * 4. 若 P 为root，则将E(k) 的左指针指向 P ，并新建一个页节点 Pr ，将 E（k）放入 Pr 并将Pr置为为root * 5. 否则 将E(k) 插入P的父页中，递归上述操作 * * @param currentPage */ private void pageSplit(Page currentPage) { if (currentPage.getElementsSize() - 1 &lt;= k &lt;&lt; 1) { return; } Element midElement = currentPage.getElement(k + 1); currentPage.getElements()[k + 1] = null; Page pn = new Page(); for (int i = k + 2; i &lt; currentPage.getElementsSize(); i++) { pn.addElement(i - k - 1, currentPage.getElement(i)); currentPage.getElements()[i] = null; } pn.getElement(0).setRightIndex(midElement.getRightIndex()); midElement.setRightIndex(pn); currentPage.setElementsSize(currentPage.getElementsSize() - k - 1); if (currentPage.getParent() == null) { Page pr = new Page(); pr.getElement(0).setRightIndex(currentPage); pr.addElement(midElement); root = pr; return; } Page parentPage = currentPage.getParent().getPage(); parentPage.addElement(midElement); pageSplit(parentPage); } private void adjust(Page currentPage) { Element parentElement = currentPage.getParent(); // root 就不用管了 if (parentElement == null) { return; } //元素个数大于等于k，也不用管 if (currentPage.getElementsSize() &gt;= k + 1) { return; } Page parentPage = parentElement.getPage(); int left = parentElement.getIndex() - 1 &lt; 0 ? parentElement.getIndex() + 1 : parentElement.getIndex(); int right = parentElement.getIndex() + 1 &gt;= parentPage.getElementsSize() ? parentElement.getIndex() : parentElement.getIndex() + 1; for (int i = left; i &lt;= right; i++) { int leftSize = parentPage.getElement(i - 1).getRightIndex().getElementsSize(); int rightSize = parentPage.getElement(i).getRightIndex().getElementsSize(); if (leftSize + rightSize - 2 &lt; k &lt;&lt; 1) { catenated(parentPage.getElement(i)); adjust(parentPage); return; } if (leftSize + rightSize - 2 &gt;= k &lt;&lt; 1) { underflow(parentPage.getElement(i)); return; } } } private void catenated(Element element) { Page leftPage = element.getPage().getElement(element.getIndex() - 1).getRightIndex(); Page rightPage = element.getRightIndex(); //删除父页中的元素 element.getPage().delete(element.getIndex()); //将删除的元素添加至右页中 rightPage.getElement(0).setV(element.getV()); for (int i = 0; i &lt; rightPage.getElementsSize(); i++) { leftPage.addElement(rightPage.getElement(i)); } } private void underflow(Element element) { Page leftPage = element.getPage().getElement(element.getIndex() - 1).getRightIndex(); Page rightPage = element.getRightIndex(); List&lt;Element&gt; tmp = new ArrayList&lt;Element&gt;(); for (int i = 0; i &lt; leftPage.getElementsSize(); i++) { tmp.add(leftPage.getElement(i)); } rightPage.getElement(0).setV(element.getV()); for (int i = 0; i &lt; rightPage.getElementsSize(); i++) { tmp.add(rightPage.getElement(i)); } //计算出中值索引 int midIndex = tmp.size() / 2; //替换元素值 element.setV(tmp.get(midIndex).getV()); tmp.get(midIndex).setV(null); //更新左页 for (int i = 1; i &lt; leftPage.getElementsSize(); i++) { leftPage.getElements()[i] = null; } leftPage.setElementsSize(1); for (int i = 1; i &lt; midIndex; i++) { leftPage.addElement(i, tmp.get(i)); } //更新右页 for (int i = 0; i &lt; rightPage.getElementsSize(); i++) { rightPage.getElements()[i] = null; } rightPage.setElementsSize(0); for (int i = midIndex; i &lt; tmp.size(); i++) { rightPage.addElement(i - midIndex, tmp.get(i)); } } public static void dfs(Page tmp) { if (tmp == null) { return; } for (int i = 0; i &lt; tmp.getElementsSize(); i++) { if (tmp.getElement(i).getV() != null) { System.out.print(&quot; &quot; + tmp.getElement(i).getV()); } dfs(tmp.getElement(i).getRightIndex()); } } public static void main(String[] args) { BTree bTree = new BTree(2); for (int i = 100; i &gt;= 1; i--) { bTree.insert(i); dfs(bTree.getRoot()); System.out.println(); } for (int i = 1; i &lt;= 25; i++) { System.out.println(bTree.search(i).getV()); } for (int i = 1; i &lt;= 25; i++) { Random random = new Random(); int x = random.nextInt(100) % 100; System.out.print(&quot;delete:&quot; + x + &quot; &quot;); System.out.println(bTree.delete(x)); dfs(bTree.getRoot()); System.out.println(); } } } B+Tree谈完了Btree我们再来谈谈B+Tree，所谓的B+Tree一直没有找到明确的出处和定义，所以这里谈的B+Tree指的是使用最多的定义，也就是mysql中innodb引擎被使用得最多的索引结构 定义B+Tree 的定义与BTree大体上一致，只有一个唯一的不同点，那就是所有的数据都保存在叶子节点中，非叶子节点中只保留索引信息 查询，插入，删除这些操作都同BTree保持一致 innodb索引的页分裂和页合并想了解在实际使用中innodb是如何管理索引树的合并和分裂的，可以查看这篇文章]]></content>
      <categories>
        <category>算法和数据结构</category>
      </categories>
      <tags>
        <tag>B-Tree</tag>
        <tag>B+Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[杂谈之什么是FullGC]]></title>
    <url>%2F2019%2F11%2F14%2Ffullgc%2F</url>
    <content type="text"><![CDATA[本文基于JDK 1.8，使用的收集器为ParNew + CMS 前言这篇文章的起因是这样的，在上周五凌晨很苦逼得参加双十一压测值班的时候，有个业务方突然打电话来说我们提供的客户端存在内存泄漏问题导致线上应用持续full gc,本来已经快要睡着的我立马就精神起来了，一通排查，最终定位到了确实是客户端有个bug会导致部分数据会被一直持有进入老年代之后gc不掉，从而就导致了老年代的频繁gc，具体bug暂且不表，有一个很奇怪的现象引起了我的注意，那就是从监控系统上来看，这个应用平均一分钟full gc次数高达十多次，按照我之前的理解full gc时是会stop the world的，stop the world的频率这么高，那么应用自身的服务已经跪掉了啊，但是看这个应用的业务指标监控，居然一切正常，这就有点超出我的理解能力了，后面为了解决这个疑问，针对什么是full gc，以及如何查看full gc的次数等查阅了很多资料，总算搞懂了full gc这个概念，在查资料的过程中发现中文社区里面包含太多错误的信息了，而且大多都是抄来抄去的，非常误导人，因此打算写一篇文章，对一些错误观点进行纠正。 正文前置知识点在真正开始探索Full GC之前，我们需要先介绍几个概念 GCGC 全称为garbage collection,中文含义为垃圾回收，在jvm中的含义为回收无用内存空间 Young space中文名为年轻代或者新生代，为JVM 堆的一部分，由分代GC概念划分而来，保存生命周期较短的对象 Tenured space中文名为老年代或年老代，为JVM 堆的一部分，由分代GC概念划分而来，保存生命周期较长的对象 Minor GCminor gc指的是发生在年轻代或者说新生代（Young space）中的gc，也有人称其为young gc或者ygc,在下文中我们统一使用minor gc表示 Major GCmajor gc指的是发生在老年代（Tenured space）中的gc，也有人称为old gc,o gc,cms gc等，在下文我们统一使用major gc表示 stop the world指的是用户线程在运行至安全点（safe point）或安全区域（safe region）之后，就自行挂起，进入暂停状态，对外的表现看起来就像是全世界都停止运转了一样,而不论何种gc算法，不论是minor gc还是major gc都会stop the world，区别只在于stop the world的时间长短。 什么是Full GC先说一下结论，Full GC这个概念是没有官方定义的，而且含义还特别混乱，在不同地方表达的含义是不同的，需要就不同的场景分别进行讨论。 大众认知上在通常意义上人们口中说的Full GC为一次特殊GC行为的描述，这次GC会回收整个堆的内存，包含老年代，新生代，metaspace等，这个是最常见的一种认知，很多人也就了解到这个程度，因此在遇到一些特殊场景的时候就会发现实际情况和自己的认知会发生冲突 从GC日志上在gc.log中会发现在部分gc日志头中也有Full GC这样的字眼，这里表示的含义是在这次GC的全过程中，都是Stop The world的状态，也就是说在这次GC的全过程中所有用户线程都是处于暂停的状态，那么在这里要喷一下中文jvm神书《深入理解JVM》了，在第二版第89页有这么一段话： GC 日志开头的“[GC”和“[Full GC”说明了这次垃圾收集的停顿类型，而不是用来区分新生代GC还是老年代GC的。如果有“Full”，说明这次GC是发生了Stop-The-World的，例如下面这段新生代收集器ParNew的日志也会出现“[Full GC”（这一般是因为出现了分配 担保失败之类的问题 .所以才导致STW)。如果是调用System.gc()方法所触发的收集，那么在这里将显示“[Full GC (System)”。 这段话的描述是错误的，因为在前面说过，不论何种gc算法，不论新生代或是老年代，其gc都会发生stop the world，这里正确的描述是这次GC的全过程都是Stop-The-World的 从JDK自带的工具上使用jstat -gc命令能够查看到制定java 线程的gc次数，那么在经过我的多次尝试以及对比之后，我发现了使用jstat 查出来的FGC 次数和时间，实际上指的是老年代的收集器发生Stop the world 的次数和持续时间，对应本文而言，就是CMS收集器的Stop the world次数和时间 其他含义（坑爹版）前面不是说到我在监控大盘上看到这个应用平均一分钟发生了十多次”Full GC”么，在我弄明白了前面两个Full GC的含义之后查看了gc.log文件，随后发现该应用实际上一次Full GC都没有出现，然后咨询了一下提供监控数据的同学，结果他说是通过JMX获取的，代码为： ManagementFactory.getGarbageCollectorMXBeans() 然后众所周知，使用MXBean获取到的只是收集器的执行次数，和Full GC半毛钱关系都没有啊，随后在追问了一下，发现做监控系统的同学直接把CMS收集器的收集次数当做了Full GC的次数来统计，what the fuck？？？？，只能说对于FUll GC的概念真的有很多人是一直没弄懂过的 结束语在这篇文章快写完的时候，用google随便搜了一下就在首页找到一篇对于各类gc概念介绍得比较透彻的文章，和使用度娘一搜首页全是各种抄来抄去的错误文章相比，对比简直是太强烈了，由此得出结论，技术类的资料能在外网查就在外网查吧，省时又省力，最后附上我找到的这篇文章貌似还是plumbr的联合创始人写的，不得不说很给力了]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>Full GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java基础篇 IO系列之File类]]></title>
    <url>%2F2019%2F11%2F09%2FFile%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[本文讨论的JDK版本为1.8.0_181，系统环境为macos FileFile 类的全限定名为 java.io.File,位于rt.jar中，正如《think in java》中介绍的那样，这个类与其叫做File，不如叫做FilePath，因为这个类除了能够表示一个文件之外，还能够表示一个目录，其实这一点也能从源码的第一行注释中看出来，注释如下： An abstract representation of file and directory pathnames 文件和目录地址的抽象表示 在开始分析之前，我们先来看看这个类的构造函数 1. private File(String pathname, int prefixLength) 2. private File(String child, File parent) 3. public File(String pathname) 4. public File(String parent, String child) 5. public File(File parent, String child) 6. public File(URI uri) 总共六个构造函数，其中2个内部的4个公共的，它们的作用都是指定该File类代表的抽象路径，区别在于拼装方式不同，下面就4个公共方法简单介绍一下： public File(String pathname) 将pathname进行标准化处理之后赋值给File类，pathname为此文件或目录的标准路径名字符串,所谓标准路径名就是指不含有重复或多于的分隔符的路径字符串，若pathname中含有多于的分隔符，File类也会把多于的分隔符给过滤掉(例如//User会被处理为/User), 同时pathname可以为相对路径(test/haha)或者绝对路径(/test/haha)，若为相对路径的话，默认的前缀为当前工作目录，也就是System.getProperty(“user.dir”) public File(String parent, String child) 其中的parent表示前缀，只能为路径字符串，child表示后缀，可以为路径字符串也可以为文件名，最终赋值给File类的字符串为 经过标准处理之后的 parent + child public File(File parent, String child) 同上一个方法是一样的，最终赋值给File类的路径为 parent的路径 + child public File(URI uri) 将URL的path赋值给File类，会校验该URL的协议头是否为”file”，若不是会抛出异常 常用方法分析好了，下面开始进入正文，正如先前所说，File类既能表示一个文件也能表示一个目录，那么我们就File类的这两种状态来分别讨论一下 作为文件创建对于文件而言，首要的功能就是创建文件了，毕竟所有的文件操作前提都是你得有个文件File类提供了三个方法用于新建文件，其中一个内部方法，两个静态方法： 1. public boolean createNewFile() 2. public static File createTempFile(String prefix, String suffix) 3. public static File createTempFile(String prefix, String suffix,File directory) public boolean createNewFile() 比较简单，主要作用就是使用创建File类时传进来的路径来创建文件，若该路径中包含的目录不存在则会直接抛异常，若该文件已经存在了则不进行任何操作 public static File createTempFile(String prefix, String suffix)底层调用的也是public static File createTempFile(String prefix, String suffix,File directory),因此我们只需要看一下public static File createTempFile(String prefix, String suffix,File directory)就好了，此方法是一个静态方法，主要作用是用来创建一个临时文件，其中prefix为文件的前缀名，suffix为文件的后缀名，directory为目录，其中前缀必须为长度大于3的字符串，并且只取文件名（例如若传入的前缀为/user/test,那么最终取的前缀为test），后缀若未传则默认为”.tmp”, directory若未传的话默认为系统临时目录，即 System.getProperty(“java.io.tmpdir”); 读写创建了文件之后，我们当然会想要来对文件进行一下读写了,但File类本身并不提供读写功能，对于Fille的读取，我们是通过后面将会提到的字节流和字符流来实现的。 作为文件的特殊情况我们已经讨论完了，接下来再看一下作为目录的情况 作为目录目录特有的操作比较简单 创建创建目录共有两个方法，分别为： 1. public boolean mkdir() 创建当前目录，若父目录不存在，则创建失败若成功创建则返回true，否则返回false 2. public boolean mkdirs() 创建当前目录，若父目录不存在则先创建父目录，若成功创建则返回true，否则返回false 遍历目录目录的遍历是作为目录而言最常用的方法，一共有5个，分别如下： 1. public String[] list() 返回当前目录下所有文件或目录名称字符串数组（不会递归遍历） 2. public String[] list(FilenameFilter filter) 返回当前目录下符合filter过滤条件的所有文件或目录名称字符串数组，其中FilenameFilter是一个接口，提供了accept方法可用于重写（不会递归遍历） 3. public File[] listFiles() 查找当前目录下所有文件或者目录，并以File类的形式返回（不会递归遍历） 4. public File[] listFiles(FilenameFilter filter) 同理，会只返回filter过滤后的File类文件 5. public File[] listFiles(FileFilter filter) 查找当前目录下所有文件或者目录，并以File类的形式返回，会只返回filter过滤后的File文件，这里的FileFilter与FilenameFilter的区别在于FilenameFilter的入参是String，而FileFilter的入参为File类 公有方法作为文件和目录都有的方法： 1. public boolean canRead() 是否可读 2. public boolean canWrite() 是否可写 3. public boolean exists() 判断当前目录或文件是否存在 4. public boolean isDirectory() 判断当前是否为目录 5. public boolean isFile() 判断当前是否为文件 6. public boolean isHidden() 是否为隐藏文件 7. public boolean delete() 删除文件或者目录，立即删除 8. public void deleteOnExit() 删除文件或者目录，当java进程退出时执行 9. public boolean renameTo(File dest) 将文件或者目录改名为传入的File类的pathName，若目标目录或者文件已存在，则返回失败]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>File类</tag>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于flag的那些事]]></title>
    <url>%2F2019%2F10%2F04%2F%E7%AB%8B%E4%B8%AAflag%E5%90%A7%2F</url>
    <content type="text"><![CDATA[周末就喜欢瞎想，虽然还有一大堆事情没有做 模拟退火与布朗运动前段时间看到了一个挺有意思的观点： 人生的优化问题可以通过数学的概念抽象为如下两点 1. 以你想成为什么样的人作为目标函数 2. 将你必须要做的事作为约束条件 上述两个条件的有无，就决定了你目前的状态到底是做的模拟退火还是布朗运动 乍一想，貌似还有那么点道理，想了一下毕业这三年来自己的一个状态，可以说算是典型的布朗运动了，每一个对未来有重大意义和影响的决定，都没有任何理由和思考，都是在周围环境或他人的影响下随波逐流，没有想清楚过自己做的这些决定与完成自己的终极目标方向是否一致，包括刚毕业时拿到offer去上海，其实那个时候根本没有想过为什么要去上海，去上海想要得到些什么，只是当时莫名地觉得去上海发展会好一点（其实也是周围人的说法，与自己而言没什么感触），然后就是最近跳槽到杭州，我又为什么要来杭州，来杭州之后我又想要得到些什么，做这些事能够帮助我实现我的最终目标吗？这些都没有想过，就像一个小分子，做着无规律的布朗运动 想一想，今年马上就25了，已经一把年纪了，是时候弄清楚自己到底想要些什么了，生活还是需要有个方向的。 梳理一下首先，就个人来说，终极目标就三个，第一个是健康的身体，第二个是充足的财富，第三个是足够的时间，相信这也是大多数人所想要的，接下来再按照这三个目标进行一下细分，梳理一下约束条件。 健康的身体要拥有一个健康的身体，除了一些不可抗因素之外，坚持做到三个方面应该就OK了 1. 良好的作息时间 2. 良好的饮食习惯 3. 合理的锻炼时间 就上述三个方面，分别制定一条约束条件 1. 拒绝熬夜，每天11点前睡觉，6~7点钟起床 2. 每日三餐，按时吃饭，避免暴饮暴食，过度油腻 3. 每日半小时锻炼时间，可跑步或其他 充足的财富那么有多少财富算是充足的财富呢，答案是再多也不够，未来会发生什么我们永远也不知道，可能现在觉得完全足够的钱在未来会变得远远不够，现在觉得非常稳定的工作到未来也可能在眨眼之间失业，所以要保证有充足的财富个人认为应该做到有这两方面 1. 保持自己的竞争力，个人成长必须跟上以及超过时间的流逝，不论何时，都能够靠个人能力赚到足够生活的钱，可以为大公司打工，也可以是作为自由职业者，总之就是能够通过劳动换来报酬。 2. 在不工作的情况下也能有源源不断的现金流，换句话说就是要有真正属于自己的事业，或者说资本，然后用资本为自己赚钱。 只要能够做到上述两点，那么随着时间的过去，总会积累下足够的财富，因为这是一个良性循环的过程。 那么就这两个方面，我们来看一下约束条件 1. 对于保持竞争力这一点，其实说起来很简单，就一句话：持续学习，确定好自己从事的专业方向，然后保持每天或是每周都花费足够的时间学习这个方向的相关知识，或是打磨技能，就能够一直保持自己的竞争力，当然这里的持续是真正意义的持续，不能因为任何原因停止 2. 对于资本，目前自己也不清楚如何建立自己的资本，唯一能想到的就是不断拓宽自己的眼界，寻找值得投资的机会 足够的时间足够的时间就是指能够有时间做自己真正想要做的事，比如，每天去一下健身房，去一下英语培训班，或者音乐班，以及和三五好友聚会，独自去旅行等等。这一项是最难以实现的，因为通常财富都是在牺牲时间的前提下换来的，举个例子，对于小码农来说，每天早上起床就是上班，下班回家之后就是睡觉，所有的时间全部在公司里面，已经和整个社会脱节了，像很普通的下班之后看个电影吃个饭，逛逛商场之类的活动对于程序员(中国的)来说是遥不可及的，因为下班的时候绝大部分店都已经关门了，因此对于程序员这类用全部时间换钱的职业来说，是不可能有充足的时间的。 那么要做到这一项，我们都些什么呢 1. 其实我们只需要有足够的财富，也就是得先实现上一个目标，并且这个实现得是建立在构建了自己的资本之后，因为为别人打工的情况下，老板总是想要花最少的钱，买你最多的时间，哪怕多出来的这些时间对他来说没有任何价值（这是因为中国大部分管理者管理能力都很低下，只把员工当做劳动密集型工种在使用），有了自己的资本之后，就会有很多人花他们的时间来为你赚钱，而你自然就会有足够的时间 那么这一条的约束条件是什么呢 其实同上一条的约束条件类似，就是一定要拥有自己的资本，就现状而言，我们可以努力提升自己的竞争力，拓宽自己的眼界，同时学会理财，积累好自己的原始资本，在有机会的情况下，毫不犹豫地去创建自己的资本 结束语梳理了这么一遍之后，为自己制定了一个新的计划，首先，按照第一个约束条件做到良好的作息时间和锻炼等，这是所有flag的前提，需要一直坚持下去，其次，平时立的一些短期flag(例如每年的计划表，每月计划表等)需要将最终目标设置为提高自己的竞争力，这样就能满足第二条约束条件，最后，多接触新鲜事物，多思考，多结识新的朋友，这样就能满足最后一条约束条件]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>随想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人对高并发服务的理解]]></title>
    <url>%2F2018%2F08%2F16%2F%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[总结一下 前言本文主要是简单介绍一下一个服务由单机部署到分布式部署，访问流量从低到高，这个过程中，我们所使用到的相关技术，以及需要主要到的点 由于本人水平极其有限，因此有什么错误的地方(感觉会有很多)欢迎大家指出 一些概念： 多核cpu以及超线程技术： 逻辑cpu核数: 物理cpu数 * cpu 核数 * 超线程数 cpu的load average：即cpu当前负载，举个栗子，若一个cpu1分钟能够处理的进程数是100，然后在这一分钟内只有20个进程需要被处理，那么当前cpu的负载为20/100 = 0.2通常一台机器的load average不应当超过0.7 * 逻辑cpu核数，当超过了就应当去查找原因，要是达到 1.0 * 逻辑cpu核数 那么就必须要想办法降下来 QPS(Query Per Second):即每秒查询率,是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准 TPS(TransactionPerSecond):即每秒事务处理量，指每秒钟系统能够处理的交易或事务的数量 提高单机性能-多线程技术：多线程是否一定能提升效率：首先需要明确一点，多线程只是将一个大的计算任务分为了多个并行的小的计算任务，这些拆分出来的任务还是需要分别去抢占cpu时间片，总体需要花费的时间并没有减少，只是使得任务可以并行执行 因此多线程能够提升程序执行效率的一个关键点是这台机器上的cpu，如果是单核的话，多线程反而比单线程慢因为增加了上下文切换的开销，同时对于多核cpu来说线程数也不是越多越好，举个例4核8线程的cpu 能够同时处理的任务也就8个，起再多线程也没用，反而会增加不必要的开销，通常来说保证同时处理的 线程数 = N(CPU核心数) + 1 能使系统效率达到最优，当然这里是指计算密集型线程，如果是io密集型的话可以适当增加线程数因为io线程并不一定会去抢占cpu 关于线程安全：什么是线程安全，感觉说法很多，个人理解线程安全问题就是你写的代码在多线程的情况下执行结果没有达到期望的目标比如hashmap在多线程的场景下在resize的时候有一定几率导致死循环，以及多个线程同时对同一个变量进行compare and set操作等总结了一下能产生线程安全的一个必要条件就是先得有多个线程同时访问并操作同一个数据，所以我们在写代码的时候需要注意当定义了一个static 类型的变量，或者是类成员变量时需要考虑是否会出现线程安全问题如果有可能出现线程安全问题，首先可以考虑一下用threadLocal能否解决问题，如果不能则需要考虑合理使用锁（不论是synchronized关键字还是lock类），但是使用锁的时候也需要注意是否会出现两个线程循环依赖，导致出现死锁的情况。 集群化服务-分布式部署：所谓分布式服务，个人理解就是服务和资源分散部署到不同的机器上使用原因是因为单机部署存在一个机器性能瓶颈，以及单点问题，所以线上所有服务都是多机部署的。当线上的流量变大了之后，以及提供服务的机器多了之后，如何去分发这些流量，以及流量都应该分发到哪台机器上这就是负载均衡解决的问题 流量转发-负载均衡：负载均衡分为4层负载均衡和7层负载均衡，其中4层负载均衡作用于OSI模型的第四层传输层，这一层主要的协议是tcp和udp，由此可以知道这一层负载均衡的作用主要是对数据包的转发通常客户端的流量过来了之后到达4层负载均衡，然后4层负载均衡通过修改数据包的地址信息将流量转发到应用服务器 7层负载均衡的话作用于OSI模型的第7层应用层，主要工作为代理，在将应用层的流量完整解析出来之后，7层负载均衡会新建一个连接到实际需要访问的机器上，将解析出的请求投递过去 公司现状：4层负载均衡使用的自研mgw，7层(web端)用的nginx或者Tengine，然后实际到service端的时候是使用的rpc服务自带的负载均衡附上一篇文章 MGW RPCRPC服务主要是为了简化部署在不同机器上的不同服务之间的相互调用不多讲，甩篇文章先 RPC 数据量日益增加-分库分表：现在线上提供服务的机器已经由一台变成多台了，并且能够水平扩展，因此在某种程度上已经解决了高访问量的问题(其实并没有)加机器就好了嘛，但接下来还是会遇到各种各样的问题首先一个比较容易想到的是当服务在线运行时间比较久或者访问量比较大之后，通常会导致数据库中或者表中的数据量越来越大，当数据量大了之后不论是插入还是查询都会变慢长此以往，直接就会导致我们的服务不可用,并且这种场景下扩几台应用机都没用，那么机智的小伙伴肯定想到了，扩应用机没用，扩DB不就行了么，答案确实是这样的，只不过我们用了一个比较高端的名词–分库分表所谓分库分表，其实就是将一个库或者表的数据分散到不同的库，或者不同的表中，然后通过提前定义好的分库规则和分表规则去访问不同库表，降低单库单表访问压力提高读写性能(ps:其实分库分表的前置技术栈还有一个读写分离技术，篇幅有限，就不说了，大致提一句就是单库写，多库读) 一些关注点分库分表的临界值 单表数量不超过1000万 单库数据量不超过300G 分库分表之后会遇到的问题 基本的数据库增删改功能 分布式id 分布式事务 动态扩容 使用zebra进行分库分表： 最后甩个链接 zebra 读多写少-缓存的使用：当把数据量的问题解决了之后，随着业务的发展服务访问量日益增加，你会发现读写分离+分库分表能处理的请求量(这里指qps或Tps，不过通常都是读压力比较大)还是有限，这就是所谓的DB瓶颈针对这种情况一个常用的优化措施就是缓存，利用缓存的高吞吐量的特性，在db前部署一层缓存可以大大降低db的负载，同时通常缓存响应的速度比db快(内存缓存)，因此在提高吞吐量的情况下还提高了访问速度，简直妙啊 redis和tair介绍:redis 纯内存K-V缓存，支持5种数据结构String、Hash 、List 、 Set 、 ZSet tair 淘宝开源 内存结构主要看存储引擎选择，例如MDB，LDB等 具体可见jiajun大佬的分享: 大佬的分享Redis AND 大佬的分享Tair 使用缓存需要注意的问题 缓存穿透通常在缓存未命中的情况下我们回去db再查一次数据，要是有人使用不存在的key来请求，那么流量就相当于直接落在db上 解决方案：访问db前进行合理性校验 缓存击穿单个key在过期的一瞬间被大量请求访问 解决方案：在访问db前，先加个互斥锁，例如setnx 缓存雪崩批量key在同一时间过期，大量请求直接到达db，然后db负载飙升，引起雪崩 解决方案：采用不同的过期时间，例如在固定过期时间的基础上加上一个随机值 不必要流程的异步化-MQ：那么在原有的系统上加上一层缓存之后就可以高枕无忧了么，答案当然是NO，下面列举一些场景： 写流量非常高 缓存通常只被用来解决读性能问题，最终数据一致性还是要靠db来保证(其实就是要把数据刷到磁盘上)，因此不可能将所有的写都放到缓存上 瞬时流量暴增 系统流量在短时间内倍增，例如节日或者活动期间，突发流量很有可能将缓存直接压垮，然后系统GG 针对这些问题，乍一看似乎是没什么好的办法可以解决了(其实有，但是我不知道)，不过针对某些特殊的场景我们还是可以优化一下的比如： 我如果能减少每个请求的处理时间，那么是不是就能够提高我单机的qps，那么瞬时流量来的时候是不是就不至于压夸整个系统了 对于写请求的话如果对于响应时间的要求不是那么高，那么先把这些请求都保存下来，然后慢慢处理不就好了 针对第一种优化方案，我们能想到的一个点是将系统流程中的一些不那么重要的分支流程由同步改为异步，例如更新缓存的操作然后第二种优化方案其实也是一种异步化的思想，将同步的事改为异步去做，只要保证最终一致性就好了。 那么怎么来实现这种异步化操作呢，这个时候就轮到MQ(MessageQueue)大佬出场了。 所谓MQ，其实就是一个生产者-消费者模型，producer负责生产消息，然后consumer消费消息，中间还有一个broker用来保存生产的消息像我们刚才说的这些场景我们可以让我们的服务器既作producer又做consumer，将需要异步处理的任务统统先发送到broker,然后慢慢取回来消费当然MQ也并没有我说的这么简单，篇幅有限加上个人能力有限我这里就不细说了，具体可以看看我司大佬的博文 这个是大佬文章 kafka介绍:我司使用的MQ是mafka，其实就是封装了一下kafka，针对kafka篇幅有限加上个人能力有限也不细说了，简单介绍一下 提升可用性-限流和熔断降级：当系统的可用性依赖与其他服务的可用性时，熔断降级机制是提升系统本身可使用性的一大利器同时针对突发流量，限流工具的使用也是相当有必要的 rhino介绍：Rhino]]></content>
  </entry>
  <entry>
    <title><![CDATA[java程序员基本素养(二) 更复杂的java程序]]></title>
    <url>%2F2018%2F07%2F19%2Fjava%E7%A8%8B%E5%BA%8F%E5%91%98%E5%9F%BA%E6%9C%AC%E7%B4%A0%E5%85%BB2%2F</url>
    <content type="text"><![CDATA[何如使用中间件，工具等只是术的层次，我们更需要关注背后的道的层次 io要写功能更强大的程序，不可避免要涉及io，不论是从文件中获取还是从网络中获取 java.io 库 待填坑 bio、nio、aio 对比 待填坑 我司大佬写的NIO 网络编程除非你一直都是写单机程序自娱自乐，不然我们总会需要将自己的服务发布到网络上 java网络编程 待填坑 多线程现在的计算机通常都不止一个CPU，同时由于CPU的超线程技术，可以使一个CPU同时处理两个线程，使得计算机的计算能力大幅提升为了更好地压榨机器的性能，多线程编程技术必不可少 Java多线程 待填坑 ThreadPoolExecutor 我写的]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>随想</tag>
        <tag>java程序员基本素养</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java程序员基本素养(一) 从java文件到在JVM中运行]]></title>
    <url>%2F2018%2F07%2F12%2Fjava%E7%A8%8B%E5%BA%8F%E5%91%98%E5%9F%BA%E6%9C%AC%E7%B4%A0%E5%85%BB%2F</url>
    <content type="text"><![CDATA[个人理解的作为一个java程序员应当有的基本素养系列，只维护一个目录作为查缺补漏用 .java 文件java 码农生涯的起点是从一个.java文件开始的 java语法 待填坑 .class 文件.java 文件通过javac编译后每个类都会生成一个.class文件.class文件是JVM生态圈里比较重要的一部分，也是java实现跨平台部署的基础 .class 文件结构 待填坑 字节码指令含义 待填坑 这个不错 java语法如何转换为字节码(不那么重要) 待填坑 .class 文件加载进内存中要使用.class文件先得把.class文件加载到内存中 类加载机制 待填坑 内存中的.class文件如何转化为机器码字节码还是能被JVM识别，但是正在进行运算的还是机器本身，所以需要把字节码转化为可被机器识别的机器码 解释器编译器，JIT等 待填坑 GC程序运行起来之后，在运行过程中需要不断地申请和释放内存，怎么来分配和回收内存就需要我们关注一下了，我们通常使用的VM都是hotspot VMhotspot VM为我们提供了很多的垃圾收集器 JVM 内存分配方案(hotSpot) 待填坑 JVM 收集器(hotSpot) 待填坑 Java 常用调试工具(jsp,jmap,jstack等) 待填坑]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>随想</tag>
        <tag>java程序员基本素养</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[innodb为什么要使用B+树做索引]]></title>
    <url>%2F2018%2F06%2F21%2Finnodb%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8B-%E6%A0%91%E5%81%9A%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[mysql 提供的存储引擎有多种，目前我只用过innodb，因此就只谈论innodb 一个疑问innodb 是采用多个辅助索引和一个聚簇索引的存储结构，其中辅助索引和聚簇索引都是采用B+树的结构来进行存储的唯一的区别在于辅助索引的叶子节点存储的是主键，而聚簇索引的叶子节点存储的是数据，那么为什么要采用B+树这种结构来存储呢，有什么好处么 个人想法 树形结构可以有效降低查询和插入效率基本维持在常数级O(logn) 对于从硬盘中读取数据的操作而言，不论是传统的机械磁盘还是ssd，随机io的开销总会大于顺序io基于内存预加载机制，及每次从磁盘加载数据到内存时总会将相邻数据一并加载到内存，通常加载到内存的数据大小为一页，若将B+树一个节点的大小设置为一页那么，查找一条记录需要进行的IO操作次数就刚好是B+树的高度，刚好B+树的高度是高度可控的。]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>随想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RPC原理]]></title>
    <url>%2F2018%2F06%2F02%2FRPC%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[原理讲解网上一大篇就不复制粘贴了 贴一篇自己觉得讲得比较清楚的 RPC原理 个人总结RPC是为了简化部署在不同机器上的不同服务之间的相互调用，使用生成动态代理类的方式，使得调用远程服务和调用本地服务并无区别，其中比较重要的点有 JDk的动态代理 服务的发布和服务不可用时下线，以及客户端如何查找可用服务等,通常使用zk实现，一个节点为一台机器 客户端和服务端之间的通信协议和报文，通常使用自定义报文,tcp协议，网络传输使用Netty通过NIO的方式通信 序列化方式的选择多种，我司默认使用hessian序列化]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>日常学习</tag>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Threadpoolexecutor源码学习]]></title>
    <url>%2F2018%2F06%2F02%2FThreadpoolexecutor%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[问题 Threadpoolexecutor 各个参数的含义 线程的创建销毁策略 如何实现 使用场景通常使用JDK的executor框架来构建线程池和提交任务 ExecutorService executorService = Executors.newFixedThreadPool(10); executorService.submit(new Callable&lt;String&gt;() { @Override public String call() throws Exception { dosomething(); return null; } }); 在executor框架中，ExecutorService有多个实现类，本文主要介绍的也是我们最常使用的为ThreadPoolExecutor 参数说明构造函数： public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; } corePoolSize 核心线程数,线程池内恒定线程数量 maximumPoolSize 最大线程数，线程池内运行存在的最大线程数 keepAliveTime 非核心线程的过期时间 unit 过期时间的单位 workQueue 用于存放任务的工作队列 threadFactory 线程工厂，用于生产线程 handler 拒绝策略，当线程池中线程达到最大数量时，对新提交的任务的拒绝策略 类结构图 ThreadPoolExecutor 继承于 AbstractExecutorService，实现了Executor以及ExecutorService接口因此同时包含submit和execute方法，我们先从最核心的execute方法来进行分析 源码分析execute方法源码如下： int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); } else if (!addWorker(command, false)) reject(command); 其中比较重要的一个变量是ctl,这是一个AtomicInteger变量，其中高3位表示线程池状态，低29位表示线程数量我们继续看源码，假设我们现在的场景是刚刚初始化了一个线程池，核心线程数为3，最大线程数为5 首先是调用workerCountOf方法来获得当前线程数，我们现在是第一次提交任务，因此当前线程数为0，小于核心线程数3，因此会执行addWorker方法我们继续debug到addWorker方法里，看看都做了些什么操作。 addWorker一共做了两个操作，我们先来看看第一部分 step 1:对ctl做cas操作增加线程数 retry: for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) { int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop } } 首先先检查了一下当前线程池的状态，若当前状态不接受新的work则直接返回false 然后就是检查当前线程数是否超过限制，对于核心线程来说是不能超过核心线程数也就是3，对于其他线程来说是不能超过最大线程数，也就是5 然后就是cas操作，增加线程数，若成功，则跳出循环 操作3在并发情况下有可能出现操作失败的场景，若失败则先检查一下当前线程池状态是否发生变化，若变化了则跳到步骤1若状态未发生变化则跳到操作2 在成功添加线程数之后就开始真正地添加任务了 step 2 添加worker boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { final ReentrantLock mainLock = this.mainLock; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) { mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int c = ctl.get(); int rs = runStateOf(c); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) { if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; } } finally { mainLock.unlock(); } if (workerAdded) { t.start(); workerStarted = true; } } } finally { if (! workerStarted) addWorkerFailed(w); } 可以看到首先是将task做为入参new了一个Worker的对象,我们先去看看Worker对象的构造函数 Worker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); } Worker是ThreadPoolExecutor的一个内部类继承了AbstractQueuedSynchronizer实现了Runnable接口构造函数做的事情就是将aqs的state置为-1，并使用我们提供的线程工厂创建一个线程，然后这里需要注意的一点是这里调用newThread方法传的参数是this，也就是说创建的所有线程实际运行的时候都是执行的Worker类的run方法 接下来就是将Worker对象添加进workers中，在添加前同样会先判断当前线程池的状态是否可以添加线程另外由于workers是一个hashSet，hashSet底层又是调用的hashmap因此是线程不安全的，所以此处还使用了一个全局的ReentrantLock来对添加方法加锁 如果添加线程成功的话，则会启动该线程，若失败的话则会调用addWorkerFailed方法，addWorkerFailed做的事就是把Worker对象从workers中移除，并将当前线程数减1同时调用tryTerminate尝试终止线程池。 tryTerminate方法主要做的事情有: 若当前线程池的状态不可终止，则不做任何事 若线程池的状态为可以终止状态，但工作队列不为空，则interrupt掉workers中的一个线程 若线程池的状态为可以终止状态且工作队列为空，将当前线程池状态置为TERMINATED 前面说到了启动线程其实是调用Worker的run方法，我们去看看run方法里面到底做了什么 run调用的是父类中的runWork方法，代码如下 Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try { while (task != null || (task = getTask()) != null) { w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try { beforeExecute(wt, task); Throwable thrown = null; try { task.run(); } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { afterExecute(task, thrown); } } finally { task = null; w.completedTasks++; w.unlock(); } } completedAbruptly = false; } finally { processWorkerExit(w, completedAbruptly); } 去掉一些不重要的逻辑我们可以看到runWork方法就是用当前线程不停地去取task，然后调用task的run方法task可以是一开始创建这个work时初始化的，也可以是调用getTask方法获取到的 getTask方法如下： boolean timedOut = false; // Did the last poll() time out? retry: for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) { decrementWorkerCount(); return null; } boolean timed; // Are workers subject to culling? for (;;) { int wc = workerCountOf(c); timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if (wc &lt;= maximumPoolSize &amp;&amp; ! (timedOut &amp;&amp; timed)) break; if (compareAndDecrementWorkerCount(c)) return null; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop } try { Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; } catch (InterruptedException retry) { timedOut = false; } } 这个方法做的事就是从一个阻塞队列中获取值，其中比较重要的一些状态的判断逻辑 当前线程池状态为SHUTDOWN并且workqueue为空，或者当前线程池状态为STOP时直接返回null 若当前线程数大于了最大线程数，减少一个线程数，并返回null 如若当前线程数大于核心线程数或者设置了允许核心线程数过期，同时从workqueue队列中取数据超时，返回null，减少一个线程数 至此，当当前线程数小于核心线程数时的全部流程我们走过一遍了，接下来我们再回到一开始的execute方法，看看当前线程数大于核心线程数时的策略 if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); } else if (!addWorker(command, false)) reject(command); 若当前线程池的状态为RUNNING并且，向workQueue中添加任务成功，则进行recheck操作 recheck操作主要是防止添加任务之后线程池状态变更，以及在设置了过期时间之后，当前线程全部过期的场景 如果添加任务失败，或者出现线程池状态变更，则进行reject操作 reject操作实际上就是调用我们自定义的或者默认的RejectedExecutionHandler 总结上面我们已经把线程池的核心代码全部梳理了一遍，下面我们就来把这些零散的东西总结一下 线程池的几种状态线程池一共有5种状态，分别为Running、ShutDown、Stop、Tidying、Terminated Running 当线程池初始化完成之后就为Running状态，此状态可以正常地接收任务并处理任务 ShutDown 当主动调用了shutdown方法之后，若当前状态为Running，则会将状态修改为ShutDown并且shutdown方法会调用 interruptIdleWorkers(false); 此方法的作用是调用当前所有线程的interrupt方法，将当前所有线程标记为中断状态然后又addWork可知，一旦当前状态不是Running的时候，是不会添加新的任务的，因此，ShutDown状态的线程池的状态是：不接受新任务添加，但会处理已有任务 Stop 当主动调用shutdownNow方法后，若当前状态为Running，或者ShutDown，则将当前状态置为Stop此状态与ShutDown的区别在于，shutdownNow方法会移除掉当前workQueue中的所有任务。因此当前状态的线程池的状态是：不接受新任务添加，且不执行未执行的任务 Tidying 当当前线程池中线程数为0，并且workQueue为空时，当前线程池状态为Tidying Terminated 当执行完terminated方法后，线程池的状态会被置为Terminated 线程池的添加策略 若当前线程数小于核心线程数则添加一个Work也就是一个线程 若当前线程数大于等于核心线程数则向workQueue也就是参数中的工作队列中添加一个task 若当前线程数大于等于核心线程数并且workQueue队列已满，则添加一个非核心线程 若当前线程数大于等于最大线程数，则使用定义好的拒绝策略拒绝掉此次任务]]></content>
      <categories>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>日常学习</tag>
        <tag>源码</tag>
        <tag>Threadpoolexecutor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[统一电话服务]]></title>
    <url>%2F2018%2F06%2F02%2F%E7%BB%9F%E4%B8%80%E7%94%B5%E8%AF%9D%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[统一电话服务模块化改造目标将现有服务按功能拆分为独立模块,内部系统结构改为各个模块之间通信的方式，减少冗余代码，解耦各个模块之间的依赖提高代码可读性和可维护性 模块划分经过对系统功能的梳理，一共划分为了如下5个互相解耦的模块，每个模块大致功能如下 校验及数据转化模块 系统中所有需要进行数据校验的操作，包括参数校验，返回值校验，以及需要进行数据转换的服务，包括16进制转10进制，码表转换等，由此模块对外提供 加解密模块 系统中所有需要进行加解密的操作，由此模块对外提供 存储模块 系统中所有需要进行存储的操作全部由此模块提供，包括缓存，db等，同时内置缓存同步策略，路由策略，降级策略，限流策略等 LeafID生成模块 系统内所有leafID的来源，内部包含预拉取，内存队列优化，熔断降级等策略 监控模块 负责监控系统运行状态，对数据进行分析并告警 模块通信方式目前采取的策略是，每个模块各对外暴露一个接口，再由内部实现类去对各个模块进行操作，其中监控模块采用AOP的方式，捕获其他所有模块的返回值及抛出的异常。 存储模块详细设计在所有模块中，存储模块是逻辑最复杂的一块，细分的话可以分为缓存模块和db模块。 缓存模块缓存模块作为高可用最重要的一环，因此相当重要，故而采取了以下策略，尽可能保证缓存服务的稳定 异地双中心部署 当一个请求到缓存模块时会判断地区信息，调用不同的缓存集群 熔断降级 采取redis、tair双缓存互为备份的方案,默认由redis提供服务，一旦redis出现异常，自动降级到tair 缓存结构优化(主要针对redis) 将string类型调整为hash类型，将key的数量级由亿降至百万，降低存储内存占用 db模块db主要用于保证数据可靠，因此重点在于不能有任何脏数据落库，除此之外还要保证db的高可用，不能被突增流量打垮，因此db模块工作如下： 限流 使用公司内部限流框架对写接口进行限流 分布式锁 落库操作其实是一类compareAndSet的操作，对于一条数据会首先查询db中有没有，没有再落库但是在并发量比较高的情况下多个线程同时写同一条数据的时候，会产生往数据库中插入同一条记录的问题,对于这个问题我们的解决方式是为每个写入操作添加一个分布式锁，过期时间为1s，当写同一条数据时，只有一个线程能获取到锁，未获取到锁的线程则等待其他线程写入，然后查询返回 leafID模块详细设计 维护线程池预拉取数据到db,数据默认从db中获取 当db中获取数据失败时，自动降级到远程调用 获取到的数据先全部缓存到内存队列中，所有外部调用都从队列中取值]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>美团点评</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK实现的动态代理源码分析]]></title>
    <url>%2F2018%2F04%2F26%2FProxy%2F</url>
    <content type="text"><![CDATA[对于懂的含义，应当是在看完之后能够自己实现出来 Spring使用的动态代理一共有两种方式，一种是基于Jdk的proxy类的只支持接口层面的代理，另一种是基于cglib能支持实现类的代理本文只讨论基于jDK的代理 问题 jdk的动态代理是如何实现的 jdk的动态代理为什么只支持接口代理 使用方式TestProxy testProxy = (TestProxy) Proxy.newProxyInstance(TestProxy.class.getClassLoader(), new Class[]{TestProxy.class}, new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(&quot;invoke method:&quot;+method.getName()+&quot; args:&quot;+args); return null; } }); testProxy.sayBye(); TestProxy.java public interface TestProxy { void sayHi(); void sayBye(); } 通常调用场景就是使用Proxy类的newProxyInstance方法，先来看看方法签名 public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) 参数有3个，含义如下: loader:类加载器，用于将生成的class文件加载进内存(方法区) interfaces:代理类要实现的接口,只支持接口，不支持实现类 h:InvocationHandler最终所有方法的调用都会走到它的invoke方法 实现实现其实很简单，核心逻辑用一句话就可以概括：使用ProxyGenerator.generateProxyClass生成二进制class文件，然后用类加载器加载进内存，最后使用构造器构造实例(ps:当前具体实现是没有这么简单的，具体实现还包括一些安全性校验，以及提高效率使用的二级缓存策略这些,但是这不是本文讨论的重点，因此暂不详细描述) 其中重点当然就是生成的代理类啦，我们在原来的代码加入下面这个一行代码，将生成的class文件保存下来 System.getProperties().put(&quot;sun.misc.ProxyGenerator.saveGeneratedFiles&quot;,&quot;true&quot;); 生成的class文件如下： $Proxy0.class package com.sun.proxy; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.lang.reflect.UndeclaredThrowableException; public final class $Proxy0 extends Proxy implements TestProxy { private static Method m1; private static Method m3; private static Method m4; private static Method m0; private static Method m2; public $Proxy0(InvocationHandler var1) throws { super(var1); } public final boolean equals(Object var1) throws { try { return ((Boolean)super.h.invoke(this, m1, new Object[]{var1})).booleanValue(); } catch (RuntimeException | Error var3) { throw var3; } catch (Throwable var4) { throw new UndeclaredThrowableException(var4); } } public final void sayBye() throws { try { super.h.invoke(this, m3, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final void sayHi() throws { try { super.h.invoke(this, m4, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final int hashCode() throws { try { return ((Integer)super.h.invoke(this, m0, (Object[])null)).intValue(); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final String toString() throws { try { return (String)super.h.invoke(this, m2, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } static { try { m1 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;equals&quot;, Class.forName(&quot;java.lang.Object&quot;)); m3 = Class.forName(&quot;TestProxy&quot;).getMethod(&quot;sayBye&quot;); m4 = Class.forName(&quot;TestProxy&quot;).getMethod(&quot;sayHi&quot;); m0 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;hashCode&quot;); m2 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;toString&quot;); } catch (NoSuchMethodException var2) { throw new NoSuchMethodError(var2.getMessage()); } catch (ClassNotFoundException var3) { throw new NoClassDefFoundError(var3.getMessage()); } } } 可以看到除了TestProxy的两个方法sayHi，sayBy之外还有hashcode,toString,equals 这三个Object类自带的方法至于为什么非要有这三个方法，我暂时也没弄明白….. 不管这个奇怪的逻辑，我们来看sayHi和sayBy 的具体实现，发现调用过程其实是先用反射拿到TestProxy的method然后调用之前传入的InvocationHandler实例的invoke方法，将对应的method和params传入,然后由实例内部的逻辑去处理 结论Q: jdk的动态代理是如何实现的A: 读取传入的interface的method信息，生成实现对应方法的字节码文件，然后具体实现就是调用传入的InvocationHandler的invoke方法 Q: jdk的动态代理为什么只支持接口代理A: 由生成的类结构可以看出，代理类是继承了Proxy类然后实现代理接口的，由于java的单继承策略,所以没办法继续继承实现类 一些思考 为什么生成的代理类要继承Proxy类? 为什么invoke方法中有一个参数是proxy这个可以参考这篇文章 若是要对类进行代理,那么应该怎么做？代理类的实现应该怎么写？]]></content>
      <categories>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>日常学习</tag>
        <tag>源码</tag>
        <tag>proxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些想法]]></title>
    <url>%2F2018%2F01%2F03%2F%E4%B8%80%E4%BA%9B%E6%83%B3%E6%B3%95%2F</url>
    <content type="text"><![CDATA[我想要的无非是看得见的未来和到得了的远方 过去独身一人，懵懂无知，得过且过 现在虽然还是一条咸鱼，还是那么无能，但是拥有了你，好像明白了很多事情 未来成为自己一直想成为的那个人，不再当一条令人恶心的咸鱼 总结人生路长，风景很多，值得我们付出所有的努力去到更远的地方，看到更好的风景 当然，最重要的是，不论旅途艰辛与否，风景动人还是令人失望，身边始终有你 — kep 于2018年1月3日晚 胡言乱语]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>随想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[咸鱼之家今天正式成立啦]]></title>
    <url>%2F2017%2F11%2F11%2Fhello-world%2F</url>
    <content type="text"><![CDATA[“双11，别人在剁手，我在码代码” 前言在换了几个大众化的博客之后终于想要自己来搭一个博客环境了。 当然作为一个只会html，css，JavaScript等单词拼写的人 写前端是不会写的，只能勉强靠着copy大佬的代码才能勉强有个能看的界面这个样子 于是周末花了一天时间找了一堆大佬们模板，最终选择了用这个看这里 毕竟反正自己不会写，用哪个都是一样的 正文以后打算在这里写一写平时自己学到的新姿势，生活中的一些瞎想等等 欢迎各位基佬前来围观 —— kep 于 2017年 11.11]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>随想</tag>
      </tags>
  </entry>
</search>
